{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook to scrape Earning Transcript from seekingAlpha.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup as BS\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Make directories \n",
    "Notice that the default path of the `Transcript` folder is in the same directory of this jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dirs\n",
    "\n",
    "sectors = ['basic-materials',\n",
    "          'conglomerates',\n",
    "          'consumer-goods',\n",
    "          'financial',\n",
    "          'healthcare',\n",
    "          'industrial-goods',\n",
    "          'services',\n",
    "          'technology',\n",
    "          'utilities']\n",
    "\n",
    "if not os.path.exists('./Transcripts'):\n",
    "    os.mkdir('Transcripts')\n",
    "for sec in sectors:\n",
    "    if not os.path.exists('Transcripts/{}'.format(sec)):\n",
    "        os.mkdir('Transcripts/{}'.format(sec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Login to Seeking Alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You probably need to manually go to the popped chrome page and **press to show you are not a robot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Trying to download new driver from http://chromedriver.storage.googleapis.com/88.0.4324.96/chromedriver_mac64.zip\n",
      "[WDM] - Unpack archive /Users/zhou/.wdm/drivers/chromedriver/88.0.4324.96/mac64/chromedriver.zip\n"
     ]
    }
   ],
   "source": [
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_experimental_option(\"useAutomationExtension\", False)\n",
    "chrome_options.add_experimental_option(\"excludeSwitches\",[\"enable-automation\"])\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install(),options=chrome_options,)\n",
    "\n",
    "driver.get(\"https://seekingalpha.com/account/login\")\n",
    "email = driver.find_element_by_name(\"email\")\n",
    "email.send_keys(\"zhouxing@uchicago.edu\")\n",
    "password = driver.find_element_by_id(\"signInPasswordField\")\n",
    "password.send_keys(\"Xz19980114!\")\n",
    "driver.find_element_by_xpath(\"//button[@type='submit']\").click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Get all the urls of transcripts under the HealthCare sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_time_name_from_title(text):\n",
    "    time_lst = re.findall(r\"Q[0-9] 2[0-9]{3}\",text)\n",
    "    name_lst = re.findall(r'\\((.+?)\\)',text)\n",
    "    return time_lst,name_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_urls(num_page_range,sector):\n",
    "    cnt = 0\n",
    "    filepath = \"Transcripts/{}/urls.txt\".format(sector)\n",
    "    if os.path.exists(filepath):\n",
    "        os.remove(filepath)\n",
    "    with open(filepath,\"a+\") as f:\n",
    "        for page in num_page_range:\n",
    "            driver.get(\"https://seekingalpha.com/earnings/earnings-call-transcripts/{}?sector={}\".format(page,sector))\n",
    "            content = driver.find_elements_by_xpath(\"//a[@sasource='earnings-center-transcripts_article']\")\n",
    "            for i in range(len(content)):\n",
    "                title = content[i].text\n",
    "                time_lst,name_lst = find_time_name_from_title(title)\n",
    "                if len(time_lst)!=1 or len(name_lst)!=1:\n",
    "                    continue\n",
    "                Time = time_lst[0].replace(\" \",\"\")\n",
    "                Name = name_lst[0]\n",
    "                url = content[i].get_attribute('href')\n",
    "                f.write(\"{};{};{}\\n\".format(Name,Time,url))\n",
    "                cnt+=1\n",
    "    f.close()\n",
    "    print(\"urls:\",cnt)                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following block, and in the prompt, type a sector among `['healthcare', 'financial', 'consumer-goods', 'conglomerates', 'services', 'technology', 'utilities', 'industrial-goods']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "sector: utilities\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "urls: 234\n"
     ]
    }
   ],
   "source": [
    "# sector and how many pages to scrape the urls\n",
    "# The values are number of pages to cover 2021 - 2020. You may need to increase it if you would like to get older transcripts.\n",
    "sec_pages = {\"healthcare\":42,\n",
    "            \"financial\":52,\n",
    "            \"consumer-goods\":24,\n",
    "             \"conglomerates\":2,\n",
    "             \"services\":48,\n",
    "             \"technology\":66,\n",
    "             \"utilities\":8,\n",
    "             'industrial-goods':26\n",
    "            }\n",
    "sector = input(\"sector:\")\n",
    "write_urls(range(sec_pages[sector]),sector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7839.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "234 / sec_pages[sector] * sum(sec_pages.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_transcipt(name,time,url,sector):\n",
    "    \n",
    "    dirpath = \"Transcripts/{}/Transcripts\".format(sector)\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.mkdir(dirpath)\n",
    "        \n",
    "    filepath = \"Transcripts/{}/Transcripts/{}_{}.txt\".format(sector,name,time)\n",
    "    \n",
    "    if os.path.exists(filepath):\n",
    "        return \n",
    "    \n",
    "    # To get the rendered DOM html, instead of the HTML\n",
    "    driver.get(url)\n",
    "    WebDriverWait(driver, 20).until(EC.visibility_of_element_located((By.XPATH, \"//div[@data-test-id='content-container']\")))\n",
    "    content = driver.page_source\n",
    "    \n",
    "    soup = BS(content)\n",
    "    result = BS(str(soup.findAll(\"div\", {\"data-test-id\" : \"content-container\"})[0]))\n",
    "    text = [i.text for i in result.findAll('p')]\n",
    "\n",
    "    with open(filepath,\"a+\") as f:\n",
    "        for line in text:\n",
    "            f.write(\"{}\\n\".format(line))\n",
    "    f.close()\n",
    "    return \"\\n\".join(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running the following block, you probably need to manually go to the popped chrome page and **press to show you are not a robot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"Transcripts/{}/urls.txt\".format(sector)\n",
    "with open(filepath,'rb') as f:\n",
    "    res = f.read().decode('ascii').split('\\n')\n",
    "    for idx,i in enumerate(res[:20]):\n",
    "        name,time,url = i.split(';')\n",
    "        try:\n",
    "            text = write_transcipt(name,time,url,sector)\n",
    "        except:\n",
    "            print(\"error:\",idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
